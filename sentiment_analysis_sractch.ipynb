{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPGBzPKVe59k50r52zoyq34",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saravanamuthu1/sentiment_analysis/blob/main/sentiment_analysis_sractch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import re"
      ],
      "metadata": {
        "id": "Rh8R3FZMpvVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsmTGAPZpG6h"
      },
      "outputs": [],
      "source": [
        "mylist=[]\n",
        "testfile = open('train-v2.tsv', 'r')\n",
        "for line in testfile:\n",
        "  value=line.rstrip(\"\\n\").split(\"\\t\")\n",
        "  mylist.append(line.rstrip(\"\\n\").split(\"\\t\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set,test_set=mylist[0:60000],mylist[60000:80000]"
      ],
      "metadata": {
        "id": "1ULncJ7Wo5gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "id": "fCD23a4B4qYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Naive_bayes:\n",
        "  def __init__(self) -> None:\n",
        "    self.mylist=[]\n",
        "    self.V_freq = None\n",
        "    self.freq_pos=None\n",
        "    self.freq_neg=None\n",
        "    self.df=None\n",
        "    self.total_porobaility_for_pos=0\n",
        "    self.total_porobaility_for_neg=0\n",
        "  def get_data_set(self,my_data):\n",
        "    self.mylist=[]\n",
        "    for line in testfile:\n",
        "      value=line.rstrip(\"\\n\").split(\"\\t\")\n",
        "      self.mylist.append(line.rstrip(\"\\n\").split(\"\\t\"))\n",
        "    self.df=pd.DataFrame(mylist)\n",
        "    self.df.columns=[\"label\",\"tweet\"]\n",
        "  def fit(self):\n",
        "    self.df['tweet'] = self.df.tweet.apply(lambda x:re.sub(r'[^\\w\\s]', '', x))\n",
        "    self.df['tweet'] = self.df.tweet.apply(lambda x:x.strip())\n",
        "    self.df['tweet'] = self.df.tweet.apply(lambda x:x.replace(\"USER\", \"\"))\n",
        "    self.df[\"tweet\"]=  self.df.tweet.apply(lambda x:\" \".join(x.split()))\n",
        "    self.df[\"tweet\"]=  self.df.tweet.apply(lambda x:''.join([i for i in x if not i.isdigit()]))\n",
        "    self.V_freq = Counter(\" \".join(self.df['tweet'].values.tolist()).split(\" \"))\n",
        "    self.freq_pos= Counter(\" \".join(self.df.loc[self.df.label=='1']['tweet'].values.tolist()).split(\" \")) \n",
        "    self.freq_neg = Counter(\" \".join(self.df.loc[self.df.label=='0']['tweet'].values.tolist()).split(\" \")) \n",
        "    self.total_porobaility_for_pos=(len(self.freq_pos)/len(self.V_freq))\n",
        "    self.total_porobaility_for_neg=(len(self.freq_neg)/len(self.V_freq))\n",
        "  def pos_word_loglikelihood_train(w):\n",
        "    if w in self.freq_pos:\n",
        "      p_w_pos=((self.freq_pos.get(w,0))/len(self.V_freq))\n",
        "      return p_w_pos\n",
        "    else:\n",
        "      return 0\n",
        "  def neg_word_loglikelihood_train(w):\n",
        "    if w in self.freq_neg:\n",
        "      p_w_neg = ((self.freq_neg.get(w,0))/len(self.V_freq))\n",
        "      return p_w_neg\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def predict(self,mytxt):\n",
        "    mytxt=mytxt.split()\n",
        "    mytxt=list(set(mytxt))\n",
        "    pos_score = self.total_porobaility_for_pos\n",
        "    neg_score = self.total_porobaility_for_neg\n",
        "    for w in mytxt:\n",
        "      pos_score= pos_score*pos_word_loglikelihood(w)\n",
        "      neg_score= neg_score*neg_word_loglikelihood(w)\n",
        "    max_value=max(pos_score,neg_score)\n",
        "    if max_value == pos_score:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    testfile = open('train-v2.tsv', 'r')\n",
        "    obj1= Naive_bayes()\n",
        "    obj1.get_data_set(testfile)\n",
        "    obj1.fit()\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1021hNONBgVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get the probability"
      ],
      "metadata": {
        "id": "tLalRUlmI6Rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wPHV6Qbtm-k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import re"
      ],
      "metadata": {
        "id": "o6K1EdiglRZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(mylist)\n",
        "\n",
        "df.columns=[\"label\",\"tweet\"]"
      ],
      "metadata": {
        "id": "ccqCVXzQ7WJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.DataFrame(train_set)\n",
        "df1.columns=[\"train_label\",\"train_value\"]"
      ],
      "metadata": {
        "id": "-YCK5eTZoO26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "si6Has3Mp5Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=pd.DataFrame(test_set)\n",
        "df2.columns=[\"test_label\",\"test_value\"]"
      ],
      "metadata": {
        "id": "RHEYKVscpQ4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "1VejeP3F9MAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_frequency=len(df1.loc[df1.train_label == '1'])\n",
        "negative_frequency=len(df1.loc[df1.train_label == \"0\"])\n",
        "print(positive_frequency)\n",
        "print(negative_frequency)"
      ],
      "metadata": {
        "id": "Vi71BrbHpXpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = df.tweet.apply(lambda x:re.sub(r'[^\\w\\s]', '', x))\n",
        "df['tweet'] = df.tweet.apply(lambda x:x.strip())\n",
        "df['tweet'] = df.tweet.apply(lambda x:x.replace(\"USER\", \"\"))\n",
        "df[\"tweet\"]= df.tweet.apply(lambda x:\" \".join(x.split()))\n",
        "df[\"tweet\"]= df.tweet.apply(lambda x:''.join([i for i in x if not i.isdigit()]))"
      ],
      "metadata": {
        "id": "vr4aeJSfICix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['train_value'] = df1.train_value.apply(lambda x:re.sub(r'[^\\w\\s]', '', x))\n",
        "df1['train_value'] = df1.train_value.apply(lambda x:x.strip())\n",
        "df1['train_value'] = df1.train_value.apply(lambda x:x.replace(\"USER\", \"\"))\n",
        "df1[\"train_value\"]= df1.train_value.apply(lambda x:\" \".join(x.split()))\n",
        "df1[\"train_value\"]= df1.train_value.apply(lambda x:''.join([i for i in x if not i.isdigit()]))"
      ],
      "metadata": {
        "id": "ADGAejjepne-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['test_value'] = df2.test_value.apply(lambda x:re.sub(r'[^\\w\\s]', '', x))\n",
        "df2['test_value'] = df2.test_value.apply(lambda x:x.strip())\n",
        "df2['test_value'] = df2.test_value.apply(lambda x:x.replace(\"USER\", \"\"))\n",
        "df2[\"test_value\"]= df2.test_value.apply(lambda x:\" \".join(x.split()))\n",
        "df2[\"test_value\"]= df2.test_value.apply(lambda x:''.join([i for i in x if not i.isdigit()]))"
      ],
      "metadata": {
        "id": "flN072503H1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['test_value']"
      ],
      "metadata": {
        "id": "ljvVMFMrqDca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V_freq = Counter(\" \".join(df['tweet'].values.tolist()).split(\" \"))\n",
        "print(len(V_freq))"
      ],
      "metadata": {
        "id": "pFptRTYF-Duu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V_freq_train=Counter(\" \".join(df1['train_value'].values.tolist()).split(\" \"))\n",
        "print(len(V_freq))"
      ],
      "metadata": {
        "id": "yZoQyU4HqNs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "li=[]\n",
        "for i in V_freq_train:\n",
        "  if len(i) == 1:\n",
        "    li.append(i)"
      ],
      "metadata": {
        "id": "pYuYzLkYIw8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_pos= Counter(\" \".join(df.loc[df.label=='1']['tweet'].values.tolist()).split(\" \")) \n",
        "\n",
        "freq_neg = Counter(\" \".join(df.loc[df.label=='0']['tweet'].values.tolist()).split(\" \")) "
      ],
      "metadata": {
        "id": "k_P9K9t2X-G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dMTbciCCI-Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_pos_train = Counter(\" \".join(df1.loc[df1.train_label=='1']['train_value'].values.tolist()).split(\" \")) \n",
        "\n",
        "freq_neg_train = Counter(\" \".join(df1.loc[df1.train_label=='0']['train_value'].values.tolist()).split(\" \")) "
      ],
      "metadata": {
        "id": "Vmwq-OQGqZna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_pos_test = Counter(\" \".join(df2.loc[df2.test_label=='1']['test_value'].values.tolist()).split(\" \")) \n",
        "\n",
        "freq_neg_test = Counter(\" \".join(df2.loc[df2.test_label=='0']['test_value'].values.tolist()).split(\" \")) "
      ],
      "metadata": {
        "id": "WA_KawjxVOJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XvAMpQXt_uRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(freq_pos_train))\n",
        "print(len(freq_neg_train))"
      ],
      "metadata": {
        "id": "VUCjPxemvMX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_porobaility_for_pos_train=((len(freq_pos_train)/len(V_freq_train)))\n",
        "print(total_porobaility_for_pos_train)\n",
        "total_porobaility_for_neg_train=(len(freq_neg_train)/len(V_freq_train))\n",
        "print(total_porobaility_for_neg_train)"
      ],
      "metadata": {
        "id": "68p-L-2uqvAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_porobaility_for_pos=np.log(len(freq_pos)/len(V_freq))\n",
        "print(total_porobaility_for_pos)\n",
        "total_porobaility_for_neg=np.log(len(freq_neg)/len(V_freq))\n",
        "print(total_porobaility_for_neg)"
      ],
      "metadata": {
        "id": "cCaEJKCNYNz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_word_loglikelihood_train(w):\n",
        "    if w in freq_pos:\n",
        "      p_w_pos=((freq_pos.get(w,0))/len(V_freq_train))\n",
        "      return p_w_pos\n",
        "    else:\n",
        "      return 0"
      ],
      "metadata": {
        "id": "5pNnUBhnrSKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neg_word_loglikelihood_train(w):\n",
        "  if w in freq_neg:\n",
        "    p_w_neg = ((freq_neg.get(w,0))/len(V_freq_train))\n",
        "    return p_w_neg\n",
        "  else:\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "ClANifjtrbcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_score_label(mytxt):\n",
        "  mytxt=mytxt.split()\n",
        "  mytxt=list(set(mytxt))\n",
        "  pos_score = total_porobaility_for_pos_train\n",
        "  neg_score = total_porobaility_for_neg_train\n",
        "  for w in mytxt:\n",
        "      pos_score= pos_score*pos_word_loglikelihood_train(w)\n",
        "      neg_score= neg_score*neg_word_loglikelihood_train(w)\n",
        "  max_value=max(pos_score,neg_score)\n",
        "  if max_value == pos_score:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n"
      ],
      "metadata": {
        "id": "LSqrW5GtDwP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S7nhB15cIaox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['total_prediction_train']=df1.train_value.apply(lambda x:total_score_label(x))\n",
        "df2['total_prediction_test']=df2.test_value.apply(lambda x:total_score_label(x))\n"
      ],
      "metadata": {
        "id": "2hdxKXGLxRlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df1['train_label'] = df1.train_label.apply(lambda x:int(x))\n",
        "accuracy1 = accuracy_score(df1['train_label'], df1['total_prediction_train'])"
      ],
      "metadata": {
        "id": "kETZTOEYvCwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1I01dnrOFgip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2['test_label'] = df2.test_label.apply(lambda x:int(x))\n",
        "accuracy2 = accuracy_score(df2['test_label'], df2['total_prediction_test'])"
      ],
      "metadata": {
        "id": "JEwpWS-Rv-fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy2"
      ],
      "metadata": {
        "id": "Bz1T3lyFwrLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy1"
      ],
      "metadata": {
        "id": "sV92FyjivzKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['total_prediction_train'].value_counts()"
      ],
      "metadata": {
        "id": "SZCJnUJiFpaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['total_prediction_test'].value_counts()"
      ],
      "metadata": {
        "id": "HPgdME8gyI_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value=df2['test_value'][0]"
      ],
      "metadata": {
        "id": "M-eT0LatV86j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZmSjVcaWZE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2x1IuO11AkY5"
      }
    }
  ]
}