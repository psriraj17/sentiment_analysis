{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmuHdWV+PkTYGssNATOYzp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saravanamuthu1/sentiment_analysis/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "y3slKIqK6tfr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import math\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Naive_bayes:\n",
        "  def __init__(self) -> None:\n",
        "    self.mylist=[]\n",
        "    self.li=[]\n",
        "    self.V_freq = None\n",
        "    self.freq_pos=None\n",
        "    self.freq_neg=None\n",
        "    self.df=None\n",
        "    self.total_porobaility_for_pos=0\n",
        "    self.total_porobaility_for_neg=0\n",
        "  def get_data_set(self,my_data):\n",
        "    for line in my_data:\n",
        "      value=line.rstrip(\"\\n\").split(\"\\t\")\n",
        "      self.mylist.append(line.rstrip(\"\\n\").split(\"\\t\"))\n",
        "    df1=pd.DataFrame(self.mylist)\n",
        "    df1.columns=[\"label\",\"tweet\"]\n",
        "    return df1,self.mylist\n",
        "  #fit function\n",
        "  def fit(self,df1):\n",
        "    df1['train_value'] = df1.train_value.apply(lambda x:re.sub(r'[^\\w\\s]', '', x))\n",
        "    df1['train_value'] = df1.train_value.apply(lambda x:x.strip())\n",
        "    df1['train_value'] =df1.train_value.apply(lambda x:x.replace(\"USER\", \"\"))\n",
        "    df1[\"train_value\"]= df1.train_value.apply(lambda x:\" \".join(x.split()))\n",
        "    df1[\"train_value\"]= df1.train_value.apply(lambda x:''.join([i for i in x if not i.isdigit()]))\n",
        "    self.V_freq = Counter(\" \".join(df1['train_value'].values.tolist()).split(\" \"))\n",
        "    self.freq_pos= Counter(\" \".join(df1.loc[df1.train_label=='1']['train_value'].values.tolist()).split(\" \")) \n",
        "    self.freq_neg = Counter(\" \".join(df1.loc[df1.train_label=='0']['train_value'].values.tolist()).split(\" \")) \n",
        "    for i in self.V_freq:\n",
        "      if i in self.freq_pos and i in self.freq_neg:\n",
        "        self.li.append(i)\n",
        "    for i in self.li:\n",
        "      self.V_freq[i] = 1\n",
        "      self.freq_pos[i] = 1\n",
        "      self.freq_neg[i] = 1\n",
        "    self.total_porobaility_for_pos=(len(self.freq_pos)/len(self.V_freq))\n",
        "    self.total_porobaility_for_neg=(len(self.freq_neg)/len(self.V_freq))\n",
        "    for i in self.V_freq:\n",
        "      if i in self.freq_pos and i in self.freq_neg:\n",
        "        self.li.append(i)\n",
        "\n",
        "  # data pre-processing\n",
        "  def pre_processing(self,mytest_file):\n",
        "    mytest_file['train_value'] = mytest_file.train_value.apply(lambda x:re.sub(r'[^\\w\\s]', '', x))\n",
        "    mytest_file['train_value'] = mytest_file.train_value.apply(lambda x:x.strip())\n",
        "    mytest_file['train_value'] =mytest_file.train_value.apply(lambda x:x.replace(\"USER\", \"\"))\n",
        "    mytest_file[\"train_value\"]= mytest_file.train_value.apply(lambda x:\" \".join(x.split()))\n",
        "    mytest_file[\"train_value\"]= mytest_file.train_value.apply(lambda x:''.join([i for i in x if not i.isdigit()]))\n",
        "    return mytest_file\n",
        "  def pre_processing_test(self,mytest_file):\n",
        "    mytest_file['test_value'] = mytest_file.test_value.apply(lambda x:re.sub(r'[^\\w\\s]', '', x))\n",
        "    mytest_file['test_value'] = mytest_file.test_value.apply(lambda x:x.strip())\n",
        "    mytest_file['test_value'] =mytest_file.test_value.apply(lambda x:x.replace(\"USER\", \"\"))\n",
        "    mytest_file[\"test_value\"]= mytest_file.test_value.apply(lambda x:\" \".join(x.split()))\n",
        "    mytest_file[\"test_value\"]= mytest_file.test_value.apply(lambda x:''.join([i for i in x if not i.isdigit()]))\n",
        "    return mytest_file\n",
        "  # predict fucntion\n",
        "  def predict(self,mytxt):\n",
        "    p_w_pos_value =0.0\n",
        "    p_w_neg_value =0.0\n",
        "    mytxt=mytxt.split()\n",
        "    mytxt=list(set(mytxt))\n",
        "    pos_score = self.total_porobaility_for_pos\n",
        "    neg_score = self.total_porobaility_for_neg\n",
        "    for w in mytxt:\n",
        "      if w in self.freq_pos:\n",
        "        p_w_pos_value=((1+(self.freq_pos.get(w,0)))/((2*1)+len(self.freq_pos)))\n",
        "      if w in self.freq_neg:\n",
        "        p_w_neg_value = ((1+(self.freq_neg.get(w,0)))/((2*1)+len(self.freq_neg)))\n",
        "      pos_score= pos_score*p_w_pos_value\n",
        "      neg_score= neg_score*p_w_neg_value\n",
        "    max_value=max(pos_score,neg_score)\n",
        "    if max_value == pos_score:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0   \n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  #to fit the data\n",
        "  testfile = open('train-v2.tsv', 'r')\n",
        "  obj1= Naive_bayes()\n",
        "  df1,total_data=obj1.get_data_set(testfile)\n",
        "  # predict values\n",
        "  # upload your dataset in the colab and change the name here to predict\n",
        "  predict_file= open('train-v2.tsv', 'r')\n",
        "  #since we don't have test set we have used split the entire corpus. we can alter still alter the program for jsut test set alone.\n",
        "  train_set,test_set=total_data[0:60000],total_data[60000:80000]\n",
        "  df2=pd.DataFrame(train_set)\n",
        "  df2.columns=[\"train_label\",\"train_value\"]\n",
        "  df2=obj1.pre_processing(df2)\n",
        "  obj1.fit(df2)\n",
        "  df2['train_label'] = df2.train_label.apply(lambda x:int(x))\n",
        "  df3=pd.DataFrame(test_set)\n",
        "  df3.columns=[\"test_label\",\"test_value\"]\n",
        "  df3=obj1.pre_processing_test(df3)\n",
        "  df2['total_prediction_train']=df2.train_value.apply(lambda x:obj1.predict(x))\n",
        "  df3['total_prediction_test']=df3.test_value.apply(lambda x:obj1.predict(x))\n",
        "  df3['test_label'] = df3.test_label.apply(lambda x:int(x))\n",
        "  accuracy1 = accuracy_score(df2['train_label'], df2['total_prediction_train'])\n",
        "  accuracy2 = accuracy_score(df3['test_label'], df3['total_prediction_test'])\n",
        "  print(\"accuracy on the trianing_set:\",accuracy1)\n",
        "  print(\"accuracy on the t_set:\",accuracy2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7exj7cWZSCMy",
        "outputId": "9e82d797-3b2a-4d5a-8d94-4b70848fd90c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on the trianing_set: 0.64465\n",
            "accuracy on the t_set: 0.5361\n"
          ]
        }
      ]
    }
  ]
}